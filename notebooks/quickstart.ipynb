{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# To use OpenAI, do the following:\n",
    "# Create a .env file and add your api key:\n",
    "##   OPENAI_API_KEY=<your_api_key>\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models.ollama import ChatOllama \n",
    "\n",
    "# llm = ChatOpenAI()\n",
    "llm = ChatOllama(model=\"llama2\", base_url=os.environ[\"OLLAMA_BASE_URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"\\nLangsmith is a language model that can assist with testing in several ways:\\n\\n1. Automated Testing: Langsmith can be used to automate testing processes, such as unit testing and integration testing. It can generate test cases based on the requirements of the software being developed, and run them automatically to identify any defects or issues.\\n2. Test Data Generation: Langsmith can be used to generate test data that can be used to test the software. For example, it can generate user inputs, Edge cases, and boundary values that can be used to test the software's functionality.\\n3. Test Case Design: Langsmith can assist in designing test cases by suggesting different approaches and strategies for testing. It can also help in identifying the most critical test cases that cover a large part of the software's functionality.\\n4. Defect Prediction: Langsmith can be used to predict potential defects in the software based on its analysis of the code and the requirements. This can help identify potential issues early on in the development process, allowing developers to address them before they become major problems.\\n5. Code Review: Langsmith can assist in reviewing the code for potential defects or security vulnerabilities. It can also suggest improvements to the code that can make it more maintainable and easier to test.\\n6. Test Automation Frameworks: Langsmith can be used to integrate with popular test automation frameworks such as Selenium, Appium, and JUnit. This allows developers to use Langsmith's language model capabilities to generate test cases and run them automatically through the framework.\\n7. Continuous Integration/Continuous Deployment: Langsmith can be used in continuous integration and deployment (CI/CD) pipelines to automate testing and ensure that the software is functioning correctly throughout the development process.\\n8. Test Data Mining: Langsmith can be used to mine test data from existing tests, this can help to reduce the time and effort required to create new test cases.\\n9. Identifying Edge Cases: Langsmith can be used to identify edge cases that may not have been considered during the development process. This can help ensure that the software handles unusual or unexpected inputs correctly.\\n10. Improving Test Coverage: Langsmith can assist in improving test coverage by identifying areas of the code that are not well tested and suggesting new test cases to cover those areas.\\n\\nBy using Langsmith for testing, developers can save time and effort, improve test coverage, and reduce the likelihood of defects making it into production.\", response_metadata={'model': 'llama2', 'created_at': '2024-03-16T08:12:13.348160829Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 41157216082, 'load_duration': 211181, 'prompt_eval_count': 12, 'prompt_eval_duration': 595072000, 'eval_count': 551, 'eval_duration': 40561471000})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how can langsmith help with testing?\"\n",
    "llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a world-class technical documentation writer, I can assist in various ways during the testing process:\\n\\n1. Content Creation: Langsmith can create clear, concise, and comprehensive test plans, test cases, and test scripts to ensure that your software or system is thoroughly tested. These documents will help you identify and fix any issues before the product launches.\\n2. Testing Support: As a writer, I can provide testing support by creating documentation for testing tools, such as automated testing frameworks or load testing tools. This documentation can include user manuals, quick-start guides, and API documentation to help your team use these tools effectively.\\n3. Quality Assurance (QA) Documentation: Langsmith can create QA documentation, such as test plans, test cases, and bug reports, to ensure that the software or system meets the required quality standards. This documentation will help you identify and fix any issues before the product is released.\\n4. User Acceptance Testing (UAT): As a writer, I can assist in creating UAT documentation, such as user manuals, quick-start guides, and API documentation, to help your team understand how to use the software or system effectively. This documentation will also help you identify any issues that users may encounter during the testing process.\\n5. Localization Support: If you are planning to release your product globally, Langsmith can assist in creating localized documentation for different regions and languages. This will ensure that your product is tested and documented accurately for each market.\\n6. Test Automation Documentation: Langsmith can create test automation documentation, such as test scripts and test plans, to help you automate testing processes more efficiently. This documentation will help you identify and fix any issues before the product is released.\\n7. Performance Testing Documentation: As a writer, I can assist in creating performance testing documentation, such as load tests, stress tests, and endurance tests. This documentation will help you identify and fix any performance issues before the product is released.\\n8. Security Testing Documentation: Langsmith can create security testing documentation, such as penetration testing reports, vulnerability assessments, and security audit reports. This documentation will help you identify and fix any security issues before the product is released.\\n9. Compliance Testing Documentation: As a writer, I can assist in creating compliance testing documentation, such as regulatory compliance reports, risk assessments, and audit reports. This documentation will help you ensure that your product meets all relevant regulatory requirements before its release.\\n10. Continuous Improvement: Langsmith can provide continuous improvement support by creating documentation for testing processes, tools, and metrics. This documentation will help you identify areas for improvement and optimize your testing processes over time.\\n\\nIn summary, as a world-class technical documentation writer, I can assist in various ways during the testing process to ensure that your product meets all quality, security, and regulatory requirements before its release.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = chain.invoke({\"input\": query})\n",
    "message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a world-class technical documentation writer, I can provide valuable insights and tools to help testers in the following ways:\n",
      "\n",
      "1. Creating Test Plans: With my expertise in writing, I can assist testers in creating comprehensive test plans that cover all aspects of a product or feature. This includes identifying test cases, prioritizing them based on risk and complexity, and outlining the resources required for testing.\n",
      "2. Developing Test Cases: I can help testers develop clear, concise, and comprehensive test cases that cover various scenarios and use cases. This ensures that all aspects of a product or feature are thoroughly tested, and any defects or issues are identified early on.\n",
      "3. Creating Test Scripts: As a technical writer, I can create detailed test scripts that outline the steps required to perform a particular test case. This includes identifying the inputs, expected outputs, and any Edge Cases that need to be addressed.\n",
      "4. Providing Technical Guidance: My expertise in technical writing allows me to provide valuable guidance on how to write clear, concise, and accurate test documentation. This includes tips on how to structure test plans, test cases, and test scripts, as well as best practices for documenting testing activities.\n",
      "5. Collaboration: As a writer, I can collaborate with testers to ensure that the test documentation is consistent and aligned with the overall testing strategy. This includes reviewing and editing test plans, test cases, and test scripts to ensure that they are accurate and up-to-date.\n",
      "6. Automating Test Documentation: Using my knowledge of technical writing, I can help automate the creation of test documentation, such as generating test cases and test scripts from requirements documents or design specifications. This can save time and reduce errors, allowing testers to focus on more critical tasks.\n",
      "7. Ensuring Compliance: As a technical writer, I can ensure that test documentation meets regulatory and compliance requirements. This includes reviewing test plans and procedures to ensure they meet industry standards and best practices.\n",
      "8. Providing Training: I can provide training to testers on how to write effective test documentation, including how to create clear and concise test cases, how to use testing tools and technologies, and how to collaborate with technical writers.\n",
      "9. Consulting: As a technical writer, I can consult with testers on how to improve their testing processes, including how to develop more comprehensive test plans, how to write better test cases, and how to automate testing activities.\n",
      "10. Content Creation: Finally, as a technical writer, I can create content that helps testers perform their jobs more efficiently. This includes creating tutorials, videos, and other educational materials that provide guidance on how to use testing tools and technologies, as well as best practices for testing.\n",
      "\n",
      "By leveraging my expertise in technical writing, Langsmith can help testers in various ways, from creating comprehensive test plans to automating test documentation, ensuring compliance, and providing training and consulting services.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"\\n\\n\\n\\n\\nLangSmith User Guide | 🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.\\nEvery playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Collecting Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production. However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Was this page helpful?PreviousLangSmithNextSetupPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\\n\\n\\n\\n\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.web_base import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector_db = Chroma.from_documents(documents, embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "template = \"\"\"Answer the question based only on the given context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the given context, Langsmith can help with testing by providing visualization and tracking of test results.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"context\": [Document(page_content=\"Langsmith can help you visualize test results and track metrics.\")],\n",
    "    \"input\": query \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "retriever = vector_db.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, LangSmith can help with testing in the following ways:\n",
      "\n",
      "1. Creating test cases: LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, that can be used to run tests on their LLM applications. These test cases can be uploaded in bulk, created on the fly, or exported from application traces.\n",
      "2. Running custom evaluations: LangSmith makes it easy to run custom evaluations (both LLM and heuristic-based) to score test results. This allows developers to evaluate their LLM applications with different evaluation metrics, such as latency, cost, and feedback scores.\n",
      "3. Debugging: When developing new LLM applications, LangSmith tracing is enabled by default. This provides clear visibility and debugging information at each step of an LLM sequence, making it easier to identify and root-cause issues. Additionally, LangSmith allows users to grow benchmarking datasets, annotate traces, and drill down into important data in trace view to debug production issues.\n",
      "4. Monitoring: LangSmith provides monitoring charts that allow users to track key metrics over time. This helps developers monitor their LLM applications' performance at scale and identify any issues that may arise.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": query})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
